---
layout: post
title:  "Understanding Large Language Models (LLMs)"
summary: "First steps using langchain"
author: remcobrilstra
date: '2024-02-26'
category: AI
thumbnail: /assets/img/posts/code.jpg
keywords: Langchain, OpenAI, Python
usemathjax: false
permalink: /blog/langchain-001/
---


### Braindump
Goal: generic overview of llm's what are the what do they do
 - Introduction
 - Whats an LLM
 - Whats a Neural Network
 - Transformers
 - Tokens
 - Hallucinations

Sources:
 - https://hackernoon.com/a-beginners-guide-to-using-large-language-models-llms-with-the-palm-api
  - https://blog.devgenius.io/understanding-tokens-and-tokenization-in-large-language-models-1058cd24b944
  - https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)
  - https://dev.to/modernsystemdesign/llm-for-dummies-3h90
  - https://arxiv.org/abs/1706.03762
  - https://www.hamzahj.com/p/llm-for-dummies-part-1
  - https://platform.openai.com/tokenizer
  - https://www.linkedin.com/pulse/what-tokens-how-calculate-them-rodrigo-andrade/
  - https://plainenglish.io/community/new-research-proves-knowledge-graphs-drastically-improve-accuracy-of-large-language-models-on-complex-data-1fc1a2
  - https://medium.com/@matti.kwan/finding-the-optimal-number-of-dimensions-for-word-embeddings-f19f71666723
  - https://medium.com/@matti.kwan/word-tokenization-as-compression-2540260f6eda
 - https://medium.com/@saschametzger/what-are-tokens-vectors-and-embeddings-how-do-you-create-them-e2a3e698e037  (check references)
 - https://million-rare.medium.com/generative-ai-for-dummies-1-3-7ff6abc72850
 ---


With all the craze about Large Language Models (LLM's) these days, i thought it would be interesting to dive in to the subject a bit. Mostly as a learning execise for myself but hopefully this will provide some value for others as well.

In this post, i want to focus on the basics, what are LLM's and what makes them tick.


## Introduction
In recent years, Large Language Models (LLMs) have revolutionized the field of natural language processing (NLP) and artificial intelligence (AI) at large. These advanced models, powered by deep learning techniques, have demonstrated remarkable capabilities in understanding and generating human-like text.

This (relativly) new technology has spawned a broad range of applications that allow people to interact with software in a natural way. They are being harowed as a paradigm shift in application development. However to properly understand what they can do and what they can't i feel it's important to have a better understanding of their internal working.

So the question i pose in this article is, what makes these models work the way they do and how can we use that to our advantage.

**Headsup:** whilst investigating the subject for this article i ended up in alot of rabbitholes for most of the subjects in here, as this is intended as a highover introduction i'll gloss over a lot of details which I intent to address in future articles.

## What are Large Language Models (LLM's)?


## Tokens?!
When reading about or working with LLM's the term 'token' is used frequently. There are limits to how many tokens a specific model is able to consume, how many they are able to produce and when paying for SaaS LLM's cost are generally based on the amount of tokens 'used'. So what are they actually?

Tokens are the fundumental elements that LLM's use to process text, they represent parts of the text that allow the LLM to represent a pieces of text in a way that is easier to process.
There are different strategies that can be used to cut-up or 'tokenize' a text for processing, which all have their pro's and con's but i'll leave the details of this for another time.

A token can be either a single character, a word, part of a word or multiple words depending on the strategy, but regardless they used as follows.

-- tokenization



## Are they Intelligent?
This is a subject that can be the source of the lively debate, which quickly tends to become philosophical. 
In the end LLM's are very good with text. they've been trained on enormous amounts of textual data and based on all that data they are able to 'predict' what the next piece/token of text will probably look like in a sequence of text. 
As this boils down to statistical analysis in the end there is always the risk of hallucination, given that the LLM's doesn't attempt to structure knowledge or understanding of a subject they simply predict what should be the piece of text given the text already available. To be fair they are extremely good at it though.

You could argue that they don't 'understand' the text but are just very good a predicting based on all the text they have seen. 
It's this argument that quickly turns to what it actually means to understand text, and how what an LLM's does differs from what i'm doing while writing this article.
I've trained myself on a lot of information on this subject and I've trained myself to structure sentences by reading a lot of them. I'm very much convinced that what i do is the result of some intelligent process going on in my head but whether or not that is in essence any more complex than what a LLM does whilst producing text I leave to others to decide.

As stated this becomes philosophical pretty quickly and i'm pretty sure others are better at that than i am, it is however an interesting thing to think about.

For now i'll just conclude that LLM's are a very useful tool for language understanding and production, which we can use to enhance the way we interact with technology in a myriad of ways.